/**
 * ä¿®å¤æ‰€æœ‰è¡¨ç»“æ„ï¼Œä½¿å…¶åŒ¹é… schema.ts å®šä¹‰
 * è¿è¡Œ: npx tsx scripts/fix-all-tables.ts
 */

import postgres from 'postgres';

const NEON_URL = 'postgresql://neondb_owner:npg_jcfQPBL2FbR7@ep-proud-mountain-ahytouvq-pooler.c-3.us-east-1.aws.neon.tech/neondb?sslmode=require';

async function fixAllTables() {
  // ä½¿ç”¨ prepare: false é¿å…ç¼“å­˜é—®é¢˜
  const sql = postgres(NEON_URL, { prepare: false });

  console.log('ğŸ”§ ä¿®å¤æ‰€æœ‰è¡¨ç»“æ„ä»¥åŒ¹é… schema.ts å®šä¹‰...\n');

  try {
    // ====== åˆ›å»ºæ‰€æœ‰éœ€è¦çš„ enum ç±»å‹ ======
    console.log('1ï¸âƒ£ åˆ›å»º enum ç±»å‹...');

    await sql.unsafe(`
      DO $$ BEGIN CREATE TYPE jlpt_level AS ENUM ('N5', 'N4', 'N3', 'N2', 'N1'); EXCEPTION WHEN duplicate_object THEN null; END $$;
    `);
    await sql.unsafe(`
      DO $$ BEGIN CREATE TYPE user_role AS ENUM ('user', 'admin'); EXCEPTION WHEN duplicate_object THEN null; END $$;
    `);
    await sql.unsafe(`
      DO $$ BEGIN CREATE TYPE source_type AS ENUM ('web', 'ai', 'textbook', 'anime', 'drama', 'other'); EXCEPTION WHEN duplicate_object THEN null; END $$;
    `);
    console.log('   âœ“ enum ç±»å‹å·²åˆ›å»º');

    // ====== ä¿®å¤ vocabulary è¡¨ ======
    console.log('\n2ï¸âƒ£ ä¿®å¤ vocabulary è¡¨...');

    // å¤‡ä»½æ•°æ®
    const vocabData = await sql`SELECT * FROM vocabulary`;
    console.log(`   å¤‡ä»½äº† ${vocabData.length} æ¡è®°å½•`);

    // åˆ é™¤å¹¶é‡å»ºè¡¨
    await sql.unsafe(`DROP TABLE IF EXISTS vocabulary CASCADE`);
    await sql.unsafe(`
      CREATE TABLE vocabulary (
        id SERIAL PRIMARY KEY,
        expression VARCHAR(255) NOT NULL,
        reading VARCHAR(255) NOT NULL,
        romaji VARCHAR(255),
        meaning TEXT NOT NULL,
        part_of_speech VARCHAR(100),
        jlpt_level jlpt_level NOT NULL,
        difficulty INTEGER DEFAULT 1,
        tags JSONB,
        category VARCHAR(50) DEFAULT 'standard',
        source VARCHAR(255),
        detailed_explanation TEXT,
        collocations JSONB,
        synonyms JSONB,
        antonyms JSONB,
        created_at TIMESTAMP NOT NULL DEFAULT NOW(),
        updated_at TIMESTAMP NOT NULL DEFAULT NOW()
      )
    `);
    console.log('   è¡¨å·²é‡å»º');

    // æ¢å¤æ•°æ®
    let vocabRestored = 0;
    for (const row of vocabData) {
      try {
        const expression = row.word || row.expression || '';
        const jlptLevel = row.level || row.jlpt_level || 'N5';
        let tagsJson = null;
        if (row.tags) {
          try {
            tagsJson = typeof row.tags === 'string' ? JSON.parse(row.tags) : row.tags;
          } catch { tagsJson = null; }
        }

        await sql`
          INSERT INTO vocabulary (id, expression, reading, meaning, part_of_speech, jlpt_level, tags, created_at, updated_at)
          VALUES (
            ${row.id}, ${expression}, ${row.reading || ''}, ${row.meaning || ''},
            ${row.partOfSpeech || row.part_of_speech || null},
            ${jlptLevel}::jlpt_level,
            ${tagsJson ? JSON.stringify(tagsJson) : null}::jsonb,
            ${row.createdAt || row.created_at || new Date()},
            ${row.updatedAt || row.updated_at || new Date()}
          )
        `;
        vocabRestored++;
        if (vocabRestored % 500 === 0) {
          process.stdout.write(`\r   æ¢å¤è¿›åº¦: ${vocabRestored}/${vocabData.length}`);
        }
      } catch (err: any) {
        // é™é»˜è·³è¿‡
      }
    }
    console.log(`\n   æ¢å¤äº† ${vocabRestored}/${vocabData.length} æ¡è®°å½•`);

    // æ›´æ–°åºåˆ—
    await sql.unsafe(`SELECT setval('vocabulary_id_seq', (SELECT COALESCE(MAX(id), 1) FROM vocabulary), true)`);

    // ====== ä¿®å¤ grammar è¡¨ ======
    console.log('\n3ï¸âƒ£ ä¿®å¤ grammar è¡¨...');

    const grammarData = await sql`SELECT * FROM grammar`;
    console.log(`   å¤‡ä»½äº† ${grammarData.length} æ¡è®°å½•`);

    await sql.unsafe(`DROP TABLE IF EXISTS grammar CASCADE`);
    await sql.unsafe(`
      CREATE TABLE grammar (
        id SERIAL PRIMARY KEY,
        pattern VARCHAR(255) NOT NULL,
        meaning TEXT NOT NULL,
        usage TEXT,
        jlpt_level jlpt_level NOT NULL,
        difficulty INTEGER DEFAULT 1,
        tags JSONB,
        created_at TIMESTAMP NOT NULL DEFAULT NOW(),
        updated_at TIMESTAMP NOT NULL DEFAULT NOW()
      )
    `);
    console.log('   è¡¨å·²é‡å»º');

    let grammarRestored = 0;
    for (const row of grammarData) {
      try {
        const jlptLevel = row.level || row.jlpt_level || 'N5';
        let tagsJson = null;
        if (row.tags) {
          try { tagsJson = typeof row.tags === 'string' ? JSON.parse(row.tags) : row.tags; } catch {}
        }

        await sql`
          INSERT INTO grammar (id, pattern, meaning, usage, jlpt_level, tags, created_at, updated_at)
          VALUES (
            ${row.id}, ${row.pattern || ''}, ${row.meaning || ''}, ${row.usage || null},
            ${jlptLevel}::jlpt_level,
            ${tagsJson ? JSON.stringify(tagsJson) : null}::jsonb,
            ${row.createdAt || row.created_at || new Date()},
            ${row.updatedAt || row.updated_at || new Date()}
          )
        `;
        grammarRestored++;
      } catch (err: any) {}
    }
    console.log(`   æ¢å¤äº† ${grammarRestored}/${grammarData.length} æ¡è®°å½•`);

    await sql.unsafe(`SELECT setval('grammar_id_seq', (SELECT COALESCE(MAX(id), 1) FROM grammar), true)`);

    // ====== ä¿®å¤ sentences è¡¨ ======
    console.log('\n4ï¸âƒ£ ä¿®å¤ sentences è¡¨...');

    const sentencesData = await sql`SELECT * FROM sentences`;
    console.log(`   å¤‡ä»½äº† ${sentencesData.length} æ¡è®°å½•`);

    await sql.unsafe(`DROP TABLE IF EXISTS sentences CASCADE`);
    await sql.unsafe(`
      CREATE TABLE sentences (
        id SERIAL PRIMARY KEY,
        japanese TEXT NOT NULL,
        reading TEXT,
        romaji TEXT,
        chinese TEXT NOT NULL,
        source VARCHAR(255),
        source_type source_type DEFAULT 'other',
        difficulty INTEGER DEFAULT 1,
        tags JSONB,
        created_at TIMESTAMP NOT NULL DEFAULT NOW()
      )
    `);
    console.log('   è¡¨å·²é‡å»º');

    let sentencesRestored = 0;
    for (const row of sentencesData) {
      try {
        await sql`
          INSERT INTO sentences (id, japanese, reading, chinese, created_at)
          VALUES (
            ${row.id}, ${row.japanese || ''}, ${row.reading || null},
            ${row.chinese || row.translation || ''},
            ${row.createdAt || row.created_at || new Date()}
          )
        `;
        sentencesRestored++;
        if (sentencesRestored % 1000 === 0) {
          process.stdout.write(`\r   æ¢å¤è¿›åº¦: ${sentencesRestored}/${sentencesData.length}`);
        }
      } catch (err: any) {}
    }
    console.log(`\n   æ¢å¤äº† ${sentencesRestored}/${sentencesData.length} æ¡è®°å½•`);

    await sql.unsafe(`SELECT setval('sentences_id_seq', (SELECT COALESCE(MAX(id), 1) FROM sentences), true)`);

    // ====== éªŒè¯ç»“æœ ======
    console.log('\n5ï¸âƒ£ éªŒè¯ç»“æœ...');

    const vocabCount = await sql`SELECT COUNT(*) as count FROM vocabulary`;
    const grammarCount = await sql`SELECT COUNT(*) as count FROM grammar`;
    const sentencesCount = await sql`SELECT COUNT(*) as count FROM sentences`;
    const usersCount = await sql`SELECT COUNT(*) as count FROM users`;

    console.log(`   vocabulary: ${vocabCount[0].count} æ¡`);
    console.log(`   grammar: ${grammarCount[0].count} æ¡`);
    console.log(`   sentences: ${sentencesCount[0].count} æ¡`);
    console.log(`   users: ${usersCount[0].count} æ¡`);

    console.log('\nâœ… æ‰€æœ‰è¡¨ä¿®å¤å®Œæˆï¼');

  } catch (err) {
    console.error('âŒ é”™è¯¯:', err);
    throw err;
  } finally {
    await sql.end();
  }
}

fixAllTables().catch(err => {
  console.error('ä¿®å¤å¤±è´¥:', err);
  process.exit(1);
});
